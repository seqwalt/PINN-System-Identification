{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that need tensorflow 1.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import scipy.io\n",
    "#from scipy.interpolate import griddata\n",
    "import time\n",
    "#from itertools import product, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, t, u1, u2,u3,u4,u5,u6, F, tau, layers):\n",
    "        \n",
    "        X = t\n",
    "        \n",
    "        self.lb = X.min(0)\n",
    "        self.ub = X.max(0)\n",
    "                \n",
    "        self.X = X\n",
    "        \n",
    "        self.t = X[:,0:1]\n",
    "        self.F = F[:,0:1]\n",
    "        self.tau = tau[:,0:1]\n",
    "        \n",
    "        self.u1 = u1\n",
    "        self.u2 = u2\n",
    "        self.u3 = u3\n",
    "        self.u4 = u4\n",
    "        self.u5 = u5\n",
    "        self.u6 = u6\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        # Initialize NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)        \n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.bv = tf.Variable([4.0], dtype=tf.float32)    \n",
    "        self.bo = tf.Variable([10.0], dtype=tf.float32)    \n",
    "        #self.m = tf.Variable([11.0], dtype=tf.float32)  \n",
    "        #self.I = tf.Variable([10.0], dtype=tf.float32)    \n",
    "        \n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        \n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
    "        self.F_tf = tf.placeholder(tf.float32, shape=[None, self.F.shape[1]])\n",
    "        self.tau_tf = tf.placeholder(tf.float32, shape=[None, self.tau.shape[1]])\n",
    "        \n",
    "        self.u1_tf = tf.placeholder(tf.float32, shape=[None, self.u1.shape[1]])\n",
    "        self.u2_tf = tf.placeholder(tf.float32, shape=[None, self.u2.shape[1]])\n",
    "        self.u3_tf = tf.placeholder(tf.float32, shape=[None, self.u3.shape[1]])\n",
    "        self.u4_tf = tf.placeholder(tf.float32, shape=[None, self.u4.shape[1]])\n",
    "        self.u5_tf = tf.placeholder(tf.float32, shape=[None, self.u5.shape[1]])\n",
    "        self.u6_tf = tf.placeholder(tf.float32, shape=[None, self.u6.shape[1]])\n",
    "        \n",
    "        self.u1_pred,self.u2_pred,self.u3_pred,self.u4_pred,self.u5_pred,self.u6_pred,\\\n",
    "        self.f_u1_pred ,self.f_u2_pred,self.f_u3_pred,self.f_u4_pred,self.f_u5_pred,self.f_u6_pred = \\\n",
    "            self.net_NS(self.t_tf, self.F_tf, self.tau_tf)\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.u1_tf - self.u1_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.u2_tf - self.u2_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.u3_tf - self.u3_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.u4_tf - self.u4_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.u5_tf - self.u5_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.u6_tf - self.u6_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u1_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u2_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u3_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u4_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u5_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u6_pred))\n",
    "                    \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 50000,\n",
    "                                                                           'maxfun': 50000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})        \n",
    "        \n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.random.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = X\n",
    "        #H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "        \n",
    "    def net_NS(self, t, F, tau):\n",
    "        bv = self.bv\n",
    "        bo = self.bo\n",
    "        m = 11.0\n",
    "        I = 10.0\n",
    "        g = 9.8\n",
    "        \n",
    "        state = self.neural_net(tf.concat([t], 1), self.weights, self.biases)\n",
    "        u1 = state[:,0:1]\n",
    "        u2 = state[:,1:2]\n",
    "        u3 = state[:,2:3]\n",
    "        u4 = state[:,3:4]\n",
    "        u5 = state[:,4:5]\n",
    "        u6 = state[:,5:6]\n",
    "        \n",
    "        \n",
    "        u1_t = tf.gradients(u1, t)[0]\n",
    "        u2_t = tf.gradients(u2, t)[0]\n",
    "        u3_t = tf.gradients(u3, t)[0]\n",
    "        u4_t = tf.gradients(u4, t)[0]\n",
    "        u5_t = tf.gradients(u5, t)[0]\n",
    "        u6_t = tf.gradients(u6, t)[0]\n",
    "\n",
    "        f_u1 = u1_t - u1 \n",
    "        f_u2 = u2_t - u2\n",
    "        f_u3 = u3_t - u3\n",
    "        f_u4 = u4_t + u4*bv/m + tf.math.multiply(tf.math.sin(u3)/m, tf.convert_to_tensor(F))\n",
    "        f_u5 = u5_t + u5*bv/m + g - tf.math.multiply(tf.math.cos(u3)/m, tf.convert_to_tensor(F))\n",
    "        f_u6 = u6_t + u6*bo/I - tf.convert_to_tensor(tau)/I\n",
    "        \n",
    "        return u1, u2, u3, u4, u5, u6, f_u1, f_u2, f_u3, f_u4, f_u5, f_u6\n",
    "    \n",
    "    def callback(self, loss, bv, bo):\n",
    "        print('Loss: %.3e, bv: %.2f, bo: %.2f' % (loss, bv, bo))\n",
    "      \n",
    "    def train(self, nIter): \n",
    "\n",
    "        tf_dict = {self.t_tf: self.t, self.u1_tf: self.u1, self.u2_tf: self.u2, self.u3_tf: self.u3, \n",
    "                   self.u4_tf: self.u4, self.u5_tf: self.u5, self.u6_tf: self.u6, self.F_tf: self.F, self.tau_tf: self.tau}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                bv_value = self.sess.run(self.bv)\n",
    "                bo_value = self.sess.run(self.bo)\n",
    "                print('It: %d, Loss: %.3e, bv: %.2f, bo: %.2f, Time: %.2f' % \n",
    "                      (it, loss_value, bv_value, bo_value, elapsed))\n",
    "                start_time = time.time()\n",
    "            \n",
    "        self.optimizer.minimize(self.sess,\n",
    "                                feed_dict = tf_dict,\n",
    "                                fetches = [self.loss, self.bv, self.bo],\n",
    "                                loss_callback = self.callback)\n",
    "            \n",
    "    \n",
    "    #def predict(self, t_star):\n",
    "        \n",
    "    #    tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star}\n",
    "        \n",
    "    #    u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "    #    v_star = self.sess.run(self.v_pred, tf_dict)\n",
    "    #    p_star = self.sess.run(self.p_pred, tf_dict)\n",
    "        \n",
    "    #    return u_star, v_star, p_star\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "# read data\n",
    "\n",
    "filepath = '../Data/'\n",
    "DATA_dict = dict()\n",
    "num_traj = 40\n",
    "for i in range(num_traj):\n",
    "    num = i+41;\n",
    "    if num >= 10:\n",
    "        str_num = str(num) # no leading zero\n",
    "    else:\n",
    "        str_num = '0'+str(num) # add leading zero\n",
    "    filename = 'trajdata_'+str_num+'.csv'\n",
    "    with open(filepath+filename, 'r') as f:\n",
    "        # remove top row, and store the rest in dictionary\n",
    "        DATA_dict[i] = np.genfromtxt(f, dtype='f4', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 23\n",
    "t = DATA_dict[idx][:,0:1]\n",
    "u1 = DATA_dict[idx][:,1:2]\n",
    "u2 = DATA_dict[idx][:,2:3]\n",
    "u3 = DATA_dict[idx][:,3:4]\n",
    "u4 = DATA_dict[idx][:,4:5]\n",
    "u5 = DATA_dict[idx][:,5:6]\n",
    "u6 = DATA_dict[idx][:,6:7]\n",
    "F = DATA_dict[idx][:,7:8]\n",
    "tau = DATA_dict[idx][:,8:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "\n",
      "It: 0, Loss: 4.507e+05, bv: 4.00, bo: 10.00, Time: 0.44\n",
      "It: 100, Loss: 4.134e+05, bv: 3.95, bo: 9.98, Time: 0.87\n",
      "It: 200, Loss: 3.922e+05, bv: 3.87, bo: 10.15, Time: 0.90\n",
      "It: 300, Loss: 3.731e+05, bv: 3.82, bo: 10.34, Time: 0.90\n",
      "It: 400, Loss: 3.536e+05, bv: 3.84, bo: 10.53, Time: 0.89\n",
      "It: 500, Loss: 3.378e+05, bv: 3.93, bo: 10.73, Time: 0.88\n",
      "It: 600, Loss: 3.309e+05, bv: 4.07, bo: 10.92, Time: 0.87\n",
      "It: 700, Loss: 3.315e+05, bv: 4.23, bo: 11.11, Time: 0.89\n",
      "It: 800, Loss: 3.301e+05, bv: 4.40, bo: 11.27, Time: 0.87\n",
      "It: 900, Loss: 3.251e+05, bv: 4.57, bo: 11.41, Time: 0.88\n",
      "It: 1000, Loss: 3.199e+05, bv: 4.74, bo: 11.54, Time: 0.87\n",
      "It: 1100, Loss: 3.147e+05, bv: 4.90, bo: 11.66, Time: 0.88\n",
      "It: 1200, Loss: 2.933e+05, bv: 5.05, bo: 11.75, Time: 0.87\n",
      "It: 1300, Loss: 2.861e+05, bv: 5.17, bo: 11.78, Time: 0.87\n",
      "It: 1400, Loss: 2.757e+05, bv: 5.27, bo: 11.79, Time: 0.87\n",
      "It: 1500, Loss: 2.661e+05, bv: 5.34, bo: 11.80, Time: 0.89\n",
      "It: 1600, Loss: 2.597e+05, bv: 5.38, bo: 11.80, Time: 0.87\n",
      "It: 1700, Loss: 2.509e+05, bv: 5.45, bo: 11.81, Time: 0.89\n",
      "It: 1800, Loss: 2.398e+05, bv: 5.52, bo: 11.85, Time: 0.87\n",
      "It: 1900, Loss: 2.217e+05, bv: 5.62, bo: 11.90, Time: 0.88\n",
      "It: 2000, Loss: 1.985e+05, bv: 5.74, bo: 11.96, Time: 0.86\n",
      "It: 2100, Loss: 1.747e+05, bv: 5.87, bo: 12.05, Time: 0.89\n",
      "It: 2200, Loss: 1.555e+05, bv: 5.99, bo: 12.15, Time: 0.88\n",
      "It: 2300, Loss: 1.398e+05, bv: 6.08, bo: 12.25, Time: 0.88\n",
      "It: 2400, Loss: 1.304e+05, bv: 6.14, bo: 12.35, Time: 0.88\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c88c2bde5ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPhysicsInformedNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-87ed547b380f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, nIter)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnIter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op_Adam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;31m# Print\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\program files (x86)\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\program files (x86)\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\program files (x86)\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\program files (x86)\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\program files (x86)\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\program files (x86)\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [1, 10,10,10, 6]\n",
    "\n",
    "# Training\n",
    "model = PhysicsInformedNN(t, u1, u2, u3, u4, u5, u6, F, tau, layers)\n",
    "model.train(200000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bv  4.929752\n",
      "bo  11.0624695\n",
      "m  10.217946\n",
      "I  11.138924\n"
     ]
    }
   ],
   "source": [
    "print('bv ',model.sess.run(model.bv)[0])\n",
    "print('bo ',model.sess.run(model.bo)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "    \n",
    "layers = [1, 10, 10, 6]\n",
    "\n",
    "# Load Data\n",
    "data = scipy.io.loadmat('../Data/cylinder_nektar_wake.mat')\n",
    "           \n",
    "U_star = data['U_star'] # N x 2 x T\n",
    "P_star = data['p_star'] # N x T\n",
    "t_star = data['t'] # T x 1\n",
    "X_star = data['X_star'] # N x 2\n",
    "    \n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "    \n",
    "# Rearrange Data \n",
    "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "TT = np.tile(t_star, (1,N)).T # N x T\n",
    "    \n",
    "UU = U_star[:,0,:] # N x T\n",
    "VV = U_star[:,1,:] # N x T\n",
    "PP = P_star # N x T\n",
    "    \n",
    "x = XX.flatten()[:,None] # NT x 1\n",
    "y = YY.flatten()[:,None] # NT x 1\n",
    "t = TT.flatten()[:,None] # NT x 1\n",
    "    \n",
    "u = UU.flatten()[:,None] # NT x 1\n",
    "v = VV.flatten()[:,None] # NT x 1\n",
    "p = PP.flatten()[:,None] # NT x 1\n",
    "    \n",
    "    ######################################################################\n",
    "    ######################## Noiseles Data ###############################\n",
    "    ######################################################################\n",
    "# Training Data    \n",
    "idx = np.random.choice(N*T, N_train, replace=False)\n",
    "x_train = x[idx,:]\n",
    "y_train = y[idx,:]\n",
    "t_train = t[idx,:]\n",
    "u_train = u[idx,:]\n",
    "v_train = v[idx,:]\n",
    "\n",
    "# Training\n",
    "model = PhysicsInformedNN(x_train, y_train, t_train, u_train, v_train, layers)\n",
    "model.train(200000)\n",
    "    \n",
    "# Test Data\n",
    "snap = np.array([100])\n",
    "x_star = X_star[:,0:1]\n",
    "y_star = X_star[:,1:2]\n",
    "t_star = TT[:,snap]\n",
    "    \n",
    "u_star = U_star[:,0,snap]\n",
    "v_star = U_star[:,1,snap]\n",
    "p_star = P_star[:,snap]\n",
    "    \n",
    "# Prediction\n",
    "u_pred, v_pred, p_pred = model.predict(x_star, y_star, t_star)\n",
    "lambda_1_value = model.sess.run(model.lambda_1)\n",
    "lambda_2_value = model.sess.run(model.lambda_2)\n",
    "    \n",
    "# Error\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)\n",
    "\n",
    "error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
    "error_lambda_2 = np.abs(lambda_2_value - 0.01)/0.01 * 100\n",
    "    \n",
    "print('Error u: %e' % (error_u))    \n",
    "print('Error v: %e' % (error_v))    \n",
    "print('Error p: %e' % (error_p))    \n",
    "print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
    "print('Error l2: %.5f%%' % (error_lambda_2))                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
